{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Learning Tasks\n",
    "#### üå∏Session 9: Deep learning with TensorFlow | Tuesday, 22/02/2022\n",
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Contents\n",
    "\n",
    "- What is TensorFlow?\n",
    "- History of Tensorflow\n",
    "- Deep Learning\n",
    "- Artificial Neural Networks\n",
    "- Loading Datasets\n",
    "- Exploring the Data\n",
    "- Pre-Process/test\n",
    "- Internezzo: correlation matrix\n",
    "\n",
    "______________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your task is to:\n",
    "\n",
    "‚Ä¢What is Responsible AI?\n",
    "\n",
    "‚Ä¢Find instances where AI has failed? Or been used maliciously or incorrectly.\n",
    "\n",
    "‚Ä¢Implications of when AI fails. There is a specific article in the GDPR Law that covers this, especially with automated decision making. (opt in and out options).\n",
    "\n",
    "‚Ä¢What should organisations do to ensure that they are being responsible with AI and the wider use of data in general?\n",
    "\n",
    "‚Ä¢Maximum 500words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responsible A.I.\n",
    "\n",
    "From \"Hey Alexa, play that song\", to hearing about Elon Musk's self-driving cars or maybe you've seen interviews with that eerie humanoid robot Erica, or simply played Chess online, we've all had exposure to Artificial intelligence. However without rules and guidance, AI can bring some pretty undesirable outcomes. Cleverbot, a once popular chatterbot, turned controversial after it started churning out the unsuitable topics it‚Äôs users had fed into it. Since it was designed to learn from human input, people began to converse with the robot inappropriately, these conversations were then held in the machine‚Äôs memory and reused either in part or full to mimic human conversation to other users, resulting in stories like this one (x). That‚Äôs where responsible A.I. comes in. As technology and society have advanced, so too have the opportunities and challenges presented by A.I and machine learning. Companies implementing and utilizing these technologies needed to be able to use AI with confidence, without the fear of facing ethical dilemmas in it‚Äôs usage. \n",
    "\n",
    "So what is Responsible A.I.? Well it‚Äôs A.I. that needs to be compliant with legal requirements and principles of fairness, reliability, safety, privacy, security and inclusiveness. It needs to be able to operate consistently under normal circumstances and in unexpected conditions. In instances where A.I impacts people‚Äôs lives we need to be able see and understand how it makes its decisions and companies need to have accountability and maintain control over their system when things go wrong, or better yet, through vigorous training and testing, predict problems before they arise on a consumer level. \n",
    "\n",
    "Now I‚Äôve already briefly mentioned the issues A.I. has presented us, but what happens when paired with the principles listed above. Let‚Äôs take this first example from syncedreview.com (y) ‚ÄúAI-Powered ‚ÄòGenderify‚Äô Platform Shut Down After Bias-Based Backlash‚Äù. This Genderify story is an example of data bias when profiling. In this case reputable titles used to filter candidates had a high return of male profiles, and ‚Äústupid‚Äù returned more female profiles. The article itself doesn‚Äôt explicitly explain how the A.I. came to these decisions, but it highlights the issue with the information the machine has been trained on. Fundamentally the Machine learning for these A.I.s is flawed in that they have been trained on data sets that are ‚Äúriddled with data gaps‚Äù. Take the medical field for example, most studies have consistently been done in depth on men, rather than women. Still to this day women often face gender bias when getting diagnosed, they are often dismissed as being hypochondriacs, hysterical or their symptoms are put down to hormones and their female anatomy just ‚Äúdoing it‚Äôs thing‚Äù so in comparison to men, there is less reliable data available to train on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = https://www.mirror.co.uk/news/uk-news/girl-7-groomed-online-robot-11907421 \n",
    "\n",
    "y = https://syncedreview.com/2021/01/01/2020-in-review-10-ai-failures/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
